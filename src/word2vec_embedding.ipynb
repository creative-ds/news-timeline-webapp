{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['1일', '오후', '10', '시', '31', '분께', '대구', '달서구...\n",
       "1    ['80대', '노모와', '지체', '장애', '를', '가진', '50대', '...\n",
       "2    ['벌초를', '위해', '산에', '올랐던', '80대', '노인이', '실종',...\n",
       "3    ['주말과', '휴일', '동안', '강원', '지역에서', '산악사고와', '교통...\n",
       "4    ['제1', '2', '3', '석유', '류', '30', '만', '보관', '...\n",
       "Name: tokenized, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "save_dir = ('../data/joongang_accident_token_df.csv')\n",
    "df = pd.read_csv(save_dir)\n",
    "df['tokenized'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# list 형태를 하고있지만 실제로는 str이기 때문에 list로 변환\n",
    "df['tokenized'] = df['tokenized'].map(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['tokenized'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1일', '오후', '10', '시', '31', '분께', '대구', '달서구의', '한', '4층짜리', '모텔', '건물', '3층', '객실에', '서', '불이', '났다', '화재', '가', '발생', '하자', '건물', '안에', '있던', '손님', '30', '여명이', '급하게', '대피했', '으나', '불이', '시작된', '객실', '안에', '있던', '40대', '남성', 'A씨', '가', '연기를', '흡입', '해', '병원', '으로', '옮겨', '졌다', '또', '객실', '안', '침대', '등이', '불에', '탔다', '소방당국은', '소방', '차', '24대와', '소방', '관', '50', '명을', '투입해', '화재', '발생', '10', '여분', '뒤인', '오후', '10', '시', '45분께', '진화', '를', '완료했다', '대구소방본부', '관계자는', '화재', '원인', '등을', '조사', '하고', '있다', '고', '밝혔다', '연합뉴스']\n",
      "['80대', '노모와', '지체', '장애', '를', '가진', '50대', '아들이', '집에서', '숨진', '채', '발견', '돼', '경찰', '이', '수사', '에', '착수했다', '1일', '서울', '강서경찰서에', '따르면', '이날', '오전', '4시께', '서울', '강서구', '의', '한', '아파트에서', '이', '집에', '사는', '80대', '여성', 'A씨', '와', '아들', '인', '50대', '남성', 'B씨', '가', '숨진', '채', '발견됐다', 'B씨', '는', 'A씨', '의', '큰아들로', '지체', '장애가', '있어', '평소', '거동이', '불편했던', '것으로', '알려졌다', '경찰', '관계자는', '모자의', '시신', '에서', '둔기', '에', '의한', '외상', '흔적', '이', '발견됐', '고', '타살', '혐의', '점이', '있다', '고', '판단', '해', '수사', '중', '이라고', '밝혔다', '이', '관계자는', '제3의', '인물에', '의한', '범행', '으로', '보고', '있다', '며', '모자', '외에', '또', '다른', '동거인이', '있었는지', '외부에', '서', '누가', '침입', '했는지', '등을', '조사', '하고', '있다', '고', '설명했다', '경찰', '은', '현장', '폐쇄회로', 'CC', 'TV', '등을', '분석', '해', '사건', '당시', '상황을', '파악', '하는', '한편', '국립과학수사연구원', '에', '시신', '부검을', '의뢰해', '정확한', '사인을', '확인', '할', '예정이다', '연합뉴스']\n",
      "['벌초를', '위해', '산에', '올랐던', '80대', '노인이', '실종', '돼', '경찰', '과', '소방당국', '이', '수색에', '나섰다', '1일', '대구소방본부에', '따르면', '이날', '오후', '1시', '41분께', '벌초를', '위해', '대구', '달성군', '가창면', '최정산에', '올랐던', 'A', '82', '씨가', '실종됐다', '는', '신고', '가', '접수됐다', '이에', '119', '특수', '구조대원', '과', '경찰', '관', '등', '80', '여명과', '수색', '견', '수색', '헬기', '를', '투입해', '6시', '간여', '동안', '수색작업을', '벌였', '지만', 'A씨', '를', '발견', '하지', '못했다', '대구소방본부', '관계자는', 'A씨', '는', '동생', '과', '함께', '벌초에', '나섰다', '가', '실종됐다', '며', '날이', '밝는', '대로', '수색을', '재개할', '예정이다', '고', '밝혔다', '연합뉴스']\n"
     ]
    }
   ],
   "source": [
    "result = [sentence for sentence in df['tokenized']]\n",
    "for line in result[:3]:\n",
    "  print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec 훈련시키기\n",
    "\n",
    "하이퍼 파라미터\n",
    "* size = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원.\n",
    "* window = 컨텍스트 윈도우 크기\n",
    "* min_count = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)\n",
    "* workers = 학습을 위한 프로세스 수\n",
    "* sg = 0은 CBOW, 1은 Skip-gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 19702740.0\n",
      "Loss after epoch 1: 14155888.0\n",
      "Loss after epoch 2: 8729156.0\n",
      "Loss after epoch 3: 8363200.0\n",
      "Loss after epoch 4: 8264448.0\n",
      "Loss after epoch 5: 7915144.0\n",
      "Loss after epoch 6: 770344.0\n",
      "Loss after epoch 7: 752736.0\n",
      "Loss after epoch 8: 726984.0\n",
      "Loss after epoch 9: 708224.0\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "class callback(CallbackAny2Vec): \n",
    "  \"\"\"Callback to print loss after each epoch.\"\"\"\n",
    "  def __init__(self):\n",
    "    self.epoch = 0\n",
    "    self.loss_to_be_subed = 0\n",
    "  def on_epoch_end(self, model):\n",
    "    loss = model.get_latest_training_loss()\n",
    "    loss_now = loss - self.loss_to_be_subed\n",
    "    self.loss_to_be_subed = loss\n",
    "    print('Loss after epoch {}: {}'.format(self.epoch, loss_now))\n",
    "    self.epoch += 1\n",
    "\n",
    "\n",
    "model = Word2Vec(sentences=result, vector_size=100, window=5, min_count=2, workers=4, sg=1, compute_loss=True, epochs=10, callbacks=[callback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수행 후 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('마구', 0.7408427596092224), ('무차별', 0.7339503765106201), ('무자비하게', 0.7324828505516052), ('폭언과', 0.7286983728408813), ('상해', 0.7243751287460327), ('때린', 0.7230818271636963), ('폭언을', 0.7211732864379883), ('보복폭행', 0.7208795547485352), ('주먹과', 0.720650851726532), ('때려', 0.7081680297851562)]\n"
     ]
    }
   ],
   "source": [
    "model_result = model.wv.most_similar(\"폭행\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장 및 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('../model/w2v_01') # 모델 저장\n",
    "loaded_model = KeyedVectors.load_word2vec_format('../model/w2v_01') # 모델 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "pretrained_model = Word2Vec.load('../model/pre_trained/word2vec') # 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('성추행', 0.8856818675994873), ('성폭행', 0.8785355687141418), ('구타', 0.8609321117401123), ('폭언', 0.8292363882064819), ('강간', 0.7983779907226562), ('협박', 0.7918735146522522), ('피해자', 0.7819958329200745), ('흉기', 0.7788309454917908), ('가해자', 0.7786863446235657), ('추행', 0.7670633792877197)]\n"
     ]
    }
   ],
   "source": [
    "model_result = pretrained_model.wv.most_similar(\"폭행\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
