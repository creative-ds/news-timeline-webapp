{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "813ed7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>topic_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14986</th>\n",
       "      <td>14986</td>\n",
       "      <td>45643</td>\n",
       "      <td>남친과 함께 잔혹하게 동거인 학대 20대 여성 구속영장</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14987</th>\n",
       "      <td>14987</td>\n",
       "      <td>45648</td>\n",
       "      <td>일왕 부부 16일 동일본대지진 피해지역 위로방문</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14988</th>\n",
       "      <td>14988</td>\n",
       "      <td>45650</td>\n",
       "      <td>1보 서울시교육청 신종코로나 확산에 개학 연기·휴업 검토</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14989</th>\n",
       "      <td>14989</td>\n",
       "      <td>45652</td>\n",
       "      <td>답변하는 배기동 국립중앙박물관장</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14990</th>\n",
       "      <td>14990</td>\n",
       "      <td>45653</td>\n",
       "      <td>2020 한국인터넷기자상 시상식 내달 1일 개최…특별상 김성후</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  index                               title  topic_idx\n",
       "14986       14986  45643      남친과 함께 잔혹하게 동거인 학대 20대 여성 구속영장          2\n",
       "14987       14987  45648          일왕 부부 16일 동일본대지진 피해지역 위로방문          4\n",
       "14988       14988  45650     1보 서울시교육청 신종코로나 확산에 개학 연기·휴업 검토          2\n",
       "14989       14989  45652                   답변하는 배기동 국립중앙박물관장          2\n",
       "14990       14990  45653  2020 한국인터넷기자상 시상식 내달 1일 개최…특별상 김성후          2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('data/dacon_news_data.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f36fd1",
   "metadata": {},
   "source": [
    "## - Tokenization: SoyNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05b53923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "\n",
    "# 한글, 영어 제외한 문자 제거\n",
    "df['title_prep'] = df['title'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-z ]\",\" \") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a13144b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            인천 핀란드 항공기 결항 휴가철 여행객 분통\n",
       "1      실리콘밸리 넘어서겠다 구글   조원 들여  전역 거점화\n",
       "2      이란 외무 긴장완화 해결책은 미국이 경제전쟁 멈추는 것\n",
       "3    NYT 클린턴 측근 기업 특수관계 조명 공과 사 맞물려종합\n",
       "4           시진핑 트럼프에 중미 무역협상 조속 타결 희망\n",
       "Name: title_prep, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title_prep'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c03d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11992,) (2999,)\n",
      "(11992,) (2999,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(df['title_prep'], df['topic_idx'], test_size=0.2, random_state=1)\n",
    "\n",
    "print(train_x.shape, test_x.shape)\n",
    "print(train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06106cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bf877a6",
   "metadata": {},
   "source": [
    "명사 추출기의 명사 점수와 Cohesion 을 함께 이용할 수도 있다.\n",
    "\n",
    "=> \"Cohesion 점수 + 명사 점수\"를 단어 점수로 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39342191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.noun import LRNounExtractor\n",
    "from soynlp.noun import LRNounExtractor_v2\n",
    "from soynlp.word import WordExtractor\n",
    "from soynlp.tokenizer import LTokenizer\n",
    "\n",
    "# noun_extractor = LRNounExtractor()\n",
    "text = train_x\n",
    "# nouns = noun_extractor.train_extract(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d95c65eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.370 Gbory 1.271 Gb\n",
      "all cohesion probabilities was computed. # words = 7491\n",
      "all branching entropies was computed # words = 10214\n",
      "all accessor variety was computed # words = 10214\n"
     ]
    }
   ],
   "source": [
    "word_extractor = WordExtractor(\n",
    "    #min_frequency=100, \n",
    "    min_cohesion_forward=0.2,\n",
    "    #min_right_branching_entropy=0.0\n",
    ")\n",
    "\n",
    "word_extractor.train(text)\n",
    "words = word_extractor.extract()\n",
    "\n",
    "cohesion_score = {word:score.cohesion_forward for word, score in words.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c212bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Noun Extractor] use default predictors\n",
      "[Noun Extractor] num features: pos=3929, neg=2321, common=107\n",
      "[Noun Extractor] counting eojeols\n",
      "[EojeolCounter] n eojeol = 30478 from 11992 sents. mem=1.371 Gb                    \n",
      "[Noun Extractor] complete eojeol counter -> lr graph\n",
      "[Noun Extractor] has been trained. #eojeols=86687, mem=1.372 Gb\n",
      "[Noun Extractor] batch prediction was completed for 6731 words\n",
      "[Noun Extractor] checked compounds. discovered 1577 compounds\n",
      "[Noun Extractor] postprocessing detaching_features : 4021 -> 3945\n",
      "[Noun Extractor] postprocessing ignore_features : 3945 -> 3913\n",
      "[Noun Extractor] postprocessing ignore_NJ : 3913 -> 3910\n",
      "[Noun Extractor] 3910 nouns (1577 compounds) with min frequency=1\n",
      "[Noun Extractor] flushing was done. mem=1.376 Gb                    \n",
      "[Noun Extractor] 50.98 % eojeols are covered\n"
     ]
    }
   ],
   "source": [
    "noun_extractor = LRNounExtractor_v2()\n",
    "nouns = noun_extractor.train_extract(text)\n",
    "\n",
    "noun_scores = {noun:score.score for noun, score in nouns.items()}\n",
    "combined_scores = {noun:score + cohesion_score.get(noun, 0)\n",
    "    for noun, score in noun_scores.items()}\n",
    "combined_scores.update(\n",
    "    {subword:cohesion for subword, cohesion in cohesion_score.items()\n",
    "    if not (subword in combined_scores)}\n",
    ")\n",
    "\n",
    "# tokenizer 생성\n",
    "tokenizer = LTokenizer(scores=combined_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea322c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_sent = []\n",
    "for i in range(len(text)):\n",
    "    sent = text.iloc[i]\n",
    "    tok_sent.append(tokenizer.tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abbc08a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['줄리아니', '러시아', '후원행사에', '돈받고', '참가', '제재', '대상도', '배석'],\n",
       " ['일왕', '신년인사', '세계', '안녕', '기원'],\n",
       " ['국토정보공사', '전남공고에', '억', '상당', '실습', '기자재', '기증'],\n",
       " ['퇴직금', '제도', '개선', '광주', '개구청', '공무직노조', '삭발투쟁'],\n",
       " ['박기수', '신임', 'TBN', '광주', '교통방송', '본부장'],\n",
       " ['또', '예측', '못', '하고', '뒷북만', '차바피해', '긴급', '지원', '해야'],\n",
       " ['게시', '판', '광주', '북부소방서', '여름철', '전기화재', '주의', '당부'],\n",
       " ['오바마', '내일', '역사', '적', '쿠바', '방문', '쿠바', '국교정상화', '대미종합'],\n",
       " ['아프리카', '연합', '수단', '군부', '에', '권력이양', '시간', '더', '주기로'],\n",
       " ['공주여고', '학생들', '등교', '안내', '하는', '김지철', '충남교육', '감']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_sent[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82edda0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_sent = []\n",
    "for doc in tok_sent:\n",
    "    nouns = [word for word in doc if word in sorted_by_score.keys()]\n",
    "    noun_sent.append(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab7fe49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['제재'],\n",
       " ['일왕', '세계', '안녕'],\n",
       " ['상당', '기증'],\n",
       " ['제도', '개선'],\n",
       " ['신임', '본부장'],\n",
       " ['예측', '못', '지원'],\n",
       " ['게시', '주의'],\n",
       " ['오바마', '역사', '쿠바', '방문', '쿠바'],\n",
       " ['아프리카', '군부'],\n",
       " ['학생들', '등교', '안내']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_sent[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "84681f58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11992"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noun_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab057a77",
   "metadata": {},
   "source": [
    "## - Word Embedding: FastText\n",
    "Fasttext의 핵심 아이디어는 단어 단위가 아닌 sub 단어를 단위로 사용합니다. 즉 다음과 같습니다.\n",
    "word2vec -> \"apple\" 학습\n",
    "\n",
    "FastText -> \"ap\", \"pp\", \"pl\", \"le\" 학습\n",
    "\n",
    "따라서 미리 학습되지 않은 단어들에 대한 vector도 표현해준다는 장점이 있습니다. 이용은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "816b7e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "\n",
    "# 1. 훈련시키기\n",
    "model = models.FastText(noun_sent, vector_size=100, window=3, workers=4, sg=1)\n",
    "\n",
    "# sg=1: skip gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b1bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.wv.key_to_index\n",
    "\n",
    "# {'명': 0,\n",
    "#  '트럼프': 1,\n",
    "#  '사망': 2,\n",
    "#  '터키': 3,\n",
    "#  '한국': 4,\n",
    "#  '년': 5,\n",
    "#  '코로나': 6,\n",
    "#  '미국': 7,\n",
    "#  '시리아': 8,\n",
    "#  '게시': 9,\n",
    "#  '정부': 10,\n",
    "#  '대통령': 11,\n",
    "#  '지원': 12,\n",
    "#  ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "da906d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pre-trained Korean fasttext\n",
    "# ko_model = models.fasttext.load_facebook_model('data/cc.ko.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4b922d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8061, 43056)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 추가 학습\n",
    "# ko_model.build_vocab(noun_sent, update=True)\n",
    "# ko_model.train(noun_sent, total_examples=len(noun_sent), epochs=ko_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ffe59896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ko_model.save('data/fasttext_ko_model')\n",
    "# ko_model.wv.save_word2vec_format('data/fasttext_ko_model_2', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "63b6da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim.models import KeyedVectors\n",
    "\n",
    "# 2. pre-trained model\n",
    "wiki_model = models.fasttext.load_facebook_model('data/wiki.ko.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "1fd15ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "879129"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_model.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "11a58845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "879129"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wiki_model.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "ec426311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107230, 215280)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추가 학습\n",
    "wiki_model.build_vocab(noun_sent, update=True)\n",
    "wiki_model.train(noun_sent, total_examples=len(noun_sent), epochs=wiki_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "cbe00573",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(879129, 879196)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_model.vocab_size, len(wiki_model.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "128d1a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7105539"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_model.wv.similarity('오바마', '대통령')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "a9225d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_model.wv.save_word2vec_format('data/fasttext_wiki_model', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c0897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "8f144b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = []\n",
    "embeddings = []\n",
    "for idx, sents in enumerate(noun_sent):\n",
    "    for word in sents:\n",
    "        embedding_vector = wiki_model.wv[word]\n",
    "        embeddings.append(embedding_vector)\n",
    "        \n",
    "    embedding_matrix.append(embeddings/len(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "b4873f4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3306199 ,  0.74296415, -0.5438936 ,  0.5470522 ,  0.07490721,\n",
       "       -0.10757225, -0.22044683, -0.01346713,  0.9021586 , -0.4260371 ,\n",
       "       -0.02638024, -0.37494206,  0.57350415,  0.17435987, -0.3515242 ,\n",
       "        0.29651707,  0.32946125,  0.47220796,  0.09709615, -0.72556275,\n",
       "        0.07250775, -0.05558758,  0.23904957, -0.19166046,  0.16046385,\n",
       "        0.07894684,  0.11156472, -0.11916998, -0.20707737,  0.23458737,\n",
       "       -0.17148274, -0.12306082,  0.8589086 , -0.784264  ,  0.01085161,\n",
       "        0.50145495,  0.11467633,  0.7191736 , -0.28603497,  0.3229578 ,\n",
       "        0.23478001, -0.7358239 , -0.5134431 , -0.41610467,  0.49158797,\n",
       "       -0.5763722 , -0.16075386, -0.4024595 ,  0.08873595,  0.16163649,\n",
       "       -0.06011597,  0.3021502 , -0.39103097, -0.46456277, -0.19158858,\n",
       "       -0.09553079, -0.40408877,  0.5471783 , -0.03515989,  0.02216857,\n",
       "        0.6114115 ,  0.08342772, -0.04666803, -0.00756682,  0.1408804 ,\n",
       "       -0.26962134,  0.48826987, -0.21538441,  0.6456442 , -0.5322079 ,\n",
       "        0.544708  ,  0.47936264, -0.08438703,  0.6926532 ,  0.4048053 ,\n",
       "       -0.29125282, -0.31507713, -0.0489548 , -0.246001  ,  0.05368699,\n",
       "        0.37726265, -0.31687608, -0.21690044,  0.22743684, -0.14136583,\n",
       "       -0.34902218,  0.20251614,  0.47224236, -0.48332834,  0.17506371,\n",
       "        0.2901026 ,  0.34313843,  0.26103532, -0.14965002, -0.10626785,\n",
       "        0.3781862 ,  0.39722067,  0.6520097 , -0.2243122 ,  0.40404266,\n",
       "        0.12929238, -0.09043469,  0.27719808, -0.24555519,  0.48093987,\n",
       "        0.26624888,  0.44555596,  0.19685084, -0.5159359 ,  0.2549916 ,\n",
       "       -0.12484676, -0.38224185,  0.51547295,  0.01954118, -0.16906105,\n",
       "       -0.15174617,  0.42079043,  0.28221217, -0.63283974,  0.14533313,\n",
       "       -0.18969554,  0.33761886, -0.2926098 , -0.4786964 , -0.44692743,\n",
       "        0.04382809, -0.5103961 ,  0.25618973,  0.34296465,  0.0689278 ,\n",
       "       -0.29966986,  0.06540662, -0.50761724,  0.06398244, -0.25417003,\n",
       "       -0.19389312, -0.40821272,  0.4373232 ,  0.09415836, -0.21929257,\n",
       "        0.1404331 , -0.21868137, -0.03668952, -0.1252734 , -0.03588949,\n",
       "        0.01063509,  0.797446  ,  0.17177947, -1.2181977 ,  0.09028949,\n",
       "       -0.06798603, -0.06380259,  0.17392632, -0.61492157,  0.50109017,\n",
       "       -0.11533926, -0.45433962,  0.9486551 , -0.43070766, -0.01434669,\n",
       "        0.4138322 ,  0.10925864,  0.10044219,  0.3291479 ,  0.15315086,\n",
       "        0.2126863 ,  0.35275215,  0.05965785, -0.21767661, -0.3192345 ,\n",
       "       -0.12914836,  0.348565  ,  0.35796598, -1.1184626 , -0.2579652 ,\n",
       "        0.2419358 , -0.48651013, -0.4609198 ,  0.04220311, -0.6329876 ,\n",
       "        0.2732674 ,  0.55324227, -0.08231376, -0.26330188,  0.5498365 ,\n",
       "       -0.20455357,  0.6265885 , -0.12353417,  0.8620025 , -1.2052408 ,\n",
       "        0.18195562,  0.7990689 ,  0.14140987,  0.08810182,  0.11240334,\n",
       "       -0.34069622, -0.07934394, -0.33853474,  0.07566682, -0.2057382 ,\n",
       "        0.05044354,  0.01721245, -0.19534896,  0.25688177, -0.44429317,\n",
       "        0.27566662,  0.06552952, -0.20500605, -0.24031766, -0.42648852,\n",
       "       -0.2956377 ,  0.06225342, -0.08230494, -0.7299988 ,  0.7573415 ,\n",
       "       -0.04440363,  0.27866423, -0.59044325, -0.04880001,  0.51006866,\n",
       "       -0.76630044, -0.19750462, -0.03180974, -0.3146125 ,  0.17661735,\n",
       "        0.41348952,  0.08395082,  0.5224423 ,  0.02164788,  0.141124  ,\n",
       "       -0.45804727,  0.24084084,  0.28718054,  0.14526767, -0.1726873 ,\n",
       "       -0.06138795,  0.04736296,  0.16115952,  0.5698272 , -0.24088094,\n",
       "        0.27919894,  0.4696196 , -0.07387681,  0.47983843, -0.2225476 ,\n",
       "        0.3305193 , -0.05987611, -0.15176982,  0.24553363, -0.5536299 ,\n",
       "       -0.11265244, -0.7798724 ,  0.357378  , -0.05201934,  0.07029717,\n",
       "       -0.2546984 , -0.01010834,  0.14717185, -0.03607676,  0.3222665 ,\n",
       "       -0.6574303 , -0.27664587,  0.20246156,  0.26211944,  0.19732939,\n",
       "        0.31901565,  0.17511594,  0.17603491, -0.2734857 ,  0.2563374 ,\n",
       "       -0.2946198 ,  0.80459183, -0.42442966,  0.1826951 ,  0.50385576,\n",
       "       -0.38583514, -0.35726133,  0.7348807 , -0.6233037 , -0.11905008,\n",
       "        0.26580256,  0.28426337, -0.02279731, -0.57685214, -0.22154081,\n",
       "       -0.27577728, -0.4702748 , -0.13608962, -0.27480936,  0.24482577,\n",
       "       -0.06287955,  0.48928356, -0.04616649,  0.09944066,  0.43646786,\n",
       "       -0.05033223, -0.68674266,  0.28317702,  0.02671995, -0.09348008],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "5cedebd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43056"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이 방법이 아냐....\n",
    "len(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4578faed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c735a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bd52d28",
   "metadata": {},
   "source": [
    "문장의 벡터 = Mean(각 단어의 벡터)\n",
    "\n",
    "단어의 벡터는 알지만, 문장의 벡터는 어떻게 표현할 수 있을까?\n",
    "\n",
    "이러한 질문의 답은, “문장의 벡터는 해당 문장의 단어들의 벡터 평균”이라고 볼 수 있다.\n",
    "\n",
    "다른/혹은 더 높은 성능을 위한 방법으로는, 문맥을 이해하는 BERT, 혹은 Doc2Vec와 같은 문장단위 임베딩, 혹은 Word2Vec의 Mean을 취한 뒤 TF-IDF를 취해주는 방법 등이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "b74dd2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>topic_idx</th>\n",
       "      <th>title_prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9724</th>\n",
       "      <td>9724</td>\n",
       "      <td>33429</td>\n",
       "      <td>줄리아니 러시아 후원행사에 돈받고 참가…美 제재대상도 배석</td>\n",
       "      <td>4</td>\n",
       "      <td>줄리아니 러시아 후원행사에 돈받고 참가   제재대상도 배석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>946</td>\n",
       "      <td>3259</td>\n",
       "      <td>일왕 신년인사…세계 안녕 기원</td>\n",
       "      <td>4</td>\n",
       "      <td>일왕 신년인사 세계 안녕 기원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10803</th>\n",
       "      <td>10803</td>\n",
       "      <td>37252</td>\n",
       "      <td>국토정보공사 전남공고에 4억 상당 실습 기자재 기증</td>\n",
       "      <td>2</td>\n",
       "      <td>국토정보공사 전남공고에  억 상당 실습 기자재 기증</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318</th>\n",
       "      <td>7318</td>\n",
       "      <td>23890</td>\n",
       "      <td>퇴직금 제도 개선 광주 5개구청 공무직노조 삭발투쟁</td>\n",
       "      <td>2</td>\n",
       "      <td>퇴직금 제도 개선 광주  개구청 공무직노조 삭발투쟁</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9386</th>\n",
       "      <td>9386</td>\n",
       "      <td>31803</td>\n",
       "      <td>박기수 신임 TBN 광주교통방송 본부장</td>\n",
       "      <td>2</td>\n",
       "      <td>박기수 신임 TBN 광주교통방송 본부장</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  index                             title  topic_idx  \\\n",
       "9724         9724  33429  줄리아니 러시아 후원행사에 돈받고 참가…美 제재대상도 배석          4   \n",
       "946           946   3259                  일왕 신년인사…세계 안녕 기원          4   \n",
       "10803       10803  37252      국토정보공사 전남공고에 4억 상당 실습 기자재 기증          2   \n",
       "7318         7318  23890      퇴직금 제도 개선 광주 5개구청 공무직노조 삭발투쟁          2   \n",
       "9386         9386  31803             박기수 신임 TBN 광주교통방송 본부장          2   \n",
       "\n",
       "                             title_prep  \n",
       "9724   줄리아니 러시아 후원행사에 돈받고 참가   제재대상도 배석  \n",
       "946                    일왕 신년인사 세계 안녕 기원  \n",
       "10803      국토정보공사 전남공고에  억 상당 실습 기자재 기증  \n",
       "7318       퇴직금 제도 개선 광주  개구청 공무직노조 삭발투쟁  \n",
       "9386              박기수 신임 TBN 광주교통방송 본부장  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df.loc[train_x.index]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "87aeeb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['noun_sent'] = 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "ab55f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.iloc[0]['noun_sent'] = noun_sent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "b527b060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9724"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "6d3b640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sents in enumerate(noun_sent):\n",
    "    train_df['noun_sent'][train_df.index[idx]] = sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "482412a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>topic_idx</th>\n",
       "      <th>title_prep</th>\n",
       "      <th>noun_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>905</td>\n",
       "      <td>3128</td>\n",
       "      <td>차세대 지휘자 찾아…서울시향 부지휘자 최초로 공개 모집</td>\n",
       "      <td>2</td>\n",
       "      <td>차세대 지휘자 찾아 서울시향 부지휘자 최초로 공개 모집</td>\n",
       "      <td>[찾아, 서울시, 향, 최초, 공개, 모집]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>5192</td>\n",
       "      <td>17075</td>\n",
       "      <td>서양화 거장 장욱진 화백 기념관 세종시에 들어선다</td>\n",
       "      <td>2</td>\n",
       "      <td>서양화 거장 장욱진 화백 기념관 세종시에 들어선다</td>\n",
       "      <td>[기념관, 세종시]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>12172</td>\n",
       "      <td>39911</td>\n",
       "      <td>내년도 최저임금 노사 입장차 팽팽</td>\n",
       "      <td>2</td>\n",
       "      <td>내년도 최저임금 노사 입장차 팽팽</td>\n",
       "      <td>[내년, 최저, 노사, 입장차, 팽팽]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>235</td>\n",
       "      <td>553</td>\n",
       "      <td>中 5G 지배하면 세계가 위험 전직 美NSC 장성 주장</td>\n",
       "      <td>4</td>\n",
       "      <td>G 지배하면 세계가 위험 전직  NSC 장성 주장</td>\n",
       "      <td>[지배, 세계, 위험, 주장]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13349</th>\n",
       "      <td>13349</td>\n",
       "      <td>42208</td>\n",
       "      <td>경주 동국대 코로나로 4·19 등반대회 취소…나무심기 대체</td>\n",
       "      <td>2</td>\n",
       "      <td>경주 동국대 코로나로      등반대회 취소 나무심기 대체</td>\n",
       "      <td>[동국대, 코로나, 취소, 나무, 대체]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  index                             title  topic_idx  \\\n",
       "905           905   3128    차세대 지휘자 찾아…서울시향 부지휘자 최초로 공개 모집          2   \n",
       "5192         5192  17075       서양화 거장 장욱진 화백 기념관 세종시에 들어선다          2   \n",
       "12172       12172  39911                내년도 최저임금 노사 입장차 팽팽          2   \n",
       "235           235    553    中 5G 지배하면 세계가 위험 전직 美NSC 장성 주장          4   \n",
       "13349       13349  42208  경주 동국대 코로나로 4·19 등반대회 취소…나무심기 대체          2   \n",
       "\n",
       "                             title_prep                 noun_sent  \n",
       "905      차세대 지휘자 찾아 서울시향 부지휘자 최초로 공개 모집  [찾아, 서울시, 향, 최초, 공개, 모집]  \n",
       "5192        서양화 거장 장욱진 화백 기념관 세종시에 들어선다                [기념관, 세종시]  \n",
       "12172                내년도 최저임금 노사 입장차 팽팽     [내년, 최저, 노사, 입장차, 팽팽]  \n",
       "235         G 지배하면 세계가 위험 전직  NSC 장성 주장          [지배, 세계, 위험, 주장]  \n",
       "13349  경주 동국대 코로나로      등반대회 취소 나무심기 대체    [동국대, 코로나, 취소, 나무, 대체]  "
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "8c338434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_mean_vector(nouns):\n",
    "    vector = []\n",
    "    for i in nouns:\n",
    "        try:\n",
    "            vector.append(wiki_model.wv[i])\n",
    "        except KeyError as e:\n",
    "            pass\n",
    "    try:\n",
    "        return np.mean(vector, axis=0)\n",
    "    except IndexError as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "49b92f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['wv'] = train_df['noun_sent'].map(get_sentence_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "5bdaa189",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>topic_idx</th>\n",
       "      <th>title_prep</th>\n",
       "      <th>noun_sent</th>\n",
       "      <th>wv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>905</td>\n",
       "      <td>3128</td>\n",
       "      <td>차세대 지휘자 찾아…서울시향 부지휘자 최초로 공개 모집</td>\n",
       "      <td>2</td>\n",
       "      <td>차세대 지휘자 찾아 서울시향 부지휘자 최초로 공개 모집</td>\n",
       "      <td>[찾아, 서울시, 향, 최초, 공개, 모집]</td>\n",
       "      <td>[-0.01482521, -0.01304319, -0.62947524, 0.0619...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>5192</td>\n",
       "      <td>17075</td>\n",
       "      <td>서양화 거장 장욱진 화백 기념관 세종시에 들어선다</td>\n",
       "      <td>2</td>\n",
       "      <td>서양화 거장 장욱진 화백 기념관 세종시에 들어선다</td>\n",
       "      <td>[기념관, 세종시]</td>\n",
       "      <td>[0.09906987, 0.29745674, -0.7595968, -0.226649...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>12172</td>\n",
       "      <td>39911</td>\n",
       "      <td>내년도 최저임금 노사 입장차 팽팽</td>\n",
       "      <td>2</td>\n",
       "      <td>내년도 최저임금 노사 입장차 팽팽</td>\n",
       "      <td>[내년, 최저, 노사, 입장차, 팽팽]</td>\n",
       "      <td>[-0.14889012, -0.07366431, -0.26153788, -0.203...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>235</td>\n",
       "      <td>553</td>\n",
       "      <td>中 5G 지배하면 세계가 위험 전직 美NSC 장성 주장</td>\n",
       "      <td>4</td>\n",
       "      <td>G 지배하면 세계가 위험 전직  NSC 장성 주장</td>\n",
       "      <td>[지배, 세계, 위험, 주장]</td>\n",
       "      <td>[-0.24608521, -0.2550412, -0.24612239, 0.00817...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13349</th>\n",
       "      <td>13349</td>\n",
       "      <td>42208</td>\n",
       "      <td>경주 동국대 코로나로 4·19 등반대회 취소…나무심기 대체</td>\n",
       "      <td>2</td>\n",
       "      <td>경주 동국대 코로나로      등반대회 취소 나무심기 대체</td>\n",
       "      <td>[동국대, 코로나, 취소, 나무, 대체]</td>\n",
       "      <td>[0.07859577, 0.23254462, -0.33864602, -0.23532...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  index                             title  topic_idx  \\\n",
       "905           905   3128    차세대 지휘자 찾아…서울시향 부지휘자 최초로 공개 모집          2   \n",
       "5192         5192  17075       서양화 거장 장욱진 화백 기념관 세종시에 들어선다          2   \n",
       "12172       12172  39911                내년도 최저임금 노사 입장차 팽팽          2   \n",
       "235           235    553    中 5G 지배하면 세계가 위험 전직 美NSC 장성 주장          4   \n",
       "13349       13349  42208  경주 동국대 코로나로 4·19 등반대회 취소…나무심기 대체          2   \n",
       "\n",
       "                             title_prep                 noun_sent  \\\n",
       "905      차세대 지휘자 찾아 서울시향 부지휘자 최초로 공개 모집  [찾아, 서울시, 향, 최초, 공개, 모집]   \n",
       "5192        서양화 거장 장욱진 화백 기념관 세종시에 들어선다                [기념관, 세종시]   \n",
       "12172                내년도 최저임금 노사 입장차 팽팽     [내년, 최저, 노사, 입장차, 팽팽]   \n",
       "235         G 지배하면 세계가 위험 전직  NSC 장성 주장          [지배, 세계, 위험, 주장]   \n",
       "13349  경주 동국대 코로나로      등반대회 취소 나무심기 대체    [동국대, 코로나, 취소, 나무, 대체]   \n",
       "\n",
       "                                                      wv  \n",
       "905    [-0.01482521, -0.01304319, -0.62947524, 0.0619...  \n",
       "5192   [0.09906987, 0.29745674, -0.7595968, -0.226649...  \n",
       "12172  [-0.14889012, -0.07366431, -0.26153788, -0.203...  \n",
       "235    [-0.24608521, -0.2550412, -0.24612239, 0.00817...  \n",
       "13349  [0.07859577, 0.23254462, -0.33864602, -0.23532...  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "a4c62019",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = train_df.wv.to_list() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fae1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "16f9c81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1599"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ca207486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13986328"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ko_model.wv.similarity('오바마', '한국')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "21971730",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = dict({})\n",
    "for key, idx in enumerate(model.wv.key_to_index):\n",
    "    my_dict[idx] = model.wv[key]\n",
    "    # Or my_dict[key] = model.wv.get_vector(key)\n",
    "    # Or my_dict[key] = model.wv.word_vec(key, use_norm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ba8e0",
   "metadata": {},
   "source": [
    "> 1차 시도 후 궁금한 사항들\n",
    "1. 직접 워드임베딩 훈련시켰을 때 왜 벡터 사이즈가 작아졌냐 (train_df size가 11~~ -> 1599) 엥?\n",
    "2. pretrained -> 추가 훈련 -> 벡터 사이즈랑 벡터의 총 길이가 왜 다르냐\n",
    "3. embedding matrix 길이와 train_df 길이가 같도록 만드는 방법 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c783d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2935c7f",
   "metadata": {},
   "source": [
    "## - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48f6e40",
   "metadata": {},
   "source": [
    "### SOM (미완성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "69171da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "from numpy import (array, unravel_index, nditer, linalg, random, subtract,\n",
    "                   power, exp, pi, zeros, arange, outer, meshgrid, dot)\n",
    "from collections import defaultdict\n",
    "from warnings import warn\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Minimalistic implementation of the Self Organizing Maps (SOM).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def fast_norm(x):\n",
    "    \"\"\"Returns norm-2 of a 1-D numpy array.\n",
    "\n",
    "    * faster than linalg.norm in case of 1-D arrays (numpy 1.9.2rc1).\n",
    "    \"\"\"\n",
    "    return sqrt(dot(x, x.T))\n",
    "\n",
    "\n",
    "class MiniSom(object):\n",
    "    def __init__(self, x, y, input_len, sigma=1.0, learning_rate=0.5, decay_function=None, random_seed=None):\n",
    "        \"\"\"\n",
    "            Initializes a Self Organizing Maps.\n",
    "\n",
    "            x,y - dimensions of the SOM\n",
    "\n",
    "            input_len - number of the elements of the vectors in input\n",
    "\n",
    "            sigma - spread of the neighborhood function (Gaussian), needs to be adequate to the dimensions of the map.\n",
    "            (at the iteration t we have sigma(t) = sigma / (1 + t/T) where T is #num_iteration/2)\n",
    "\n",
    "            learning_rate - initial learning rate\n",
    "            (at the iteration t we have learning_rate(t) = learning_rate / (1 + t/T) where T is #num_iteration/2)\n",
    "\n",
    "            decay_function, function that reduces learning_rate and sigma at each iteration\n",
    "                            default function: lambda x,current_iteration,max_iter: x/(1+current_iteration/max_iter)\n",
    "\n",
    "            random_seed, random seed to use.\n",
    "        \"\"\"\n",
    "        if sigma >= x/2.0 or sigma >= y/2.0:\n",
    "            warn('Warning: sigma is too high for the dimension of the map.')\n",
    "        if random_seed:\n",
    "            self.random_generator = random.RandomState(random_seed)\n",
    "        else:\n",
    "            self.random_generator = random.RandomState(random_seed)\n",
    "        if decay_function:\n",
    "            self._decay_function = decay_function\n",
    "        else:\n",
    "            self._decay_function = lambda x, t, max_iter: x/(1+t/max_iter)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.sigma = sigma\n",
    "        self.weights = self.random_generator.rand(x,y,input_len)*2-1 # random initialization\n",
    "        for i in range(x):\n",
    "            for j in range(y):\n",
    "                self.weights[i,j] = self.weights[i,j] / fast_norm(self.weights[i,j]) # normalization\n",
    "        self.activation_map = zeros((x,y))\n",
    "        self.neigx = arange(x)\n",
    "        self.neigy = arange(y) # used to evaluate the neighborhood function\n",
    "        self.neighborhood = self.gaussian\n",
    "\n",
    "    def _activate(self, x):\n",
    "        \"\"\" Updates matrix activation_map, in this matrix the element i,j is the response of the neuron i,j to x \"\"\"\n",
    "        s = subtract(x, self.weights) # x - w\n",
    "        it = nditer(self.activation_map, flags=['multi_index'])\n",
    "        while not it.finished:\n",
    "            self.activation_map[it.multi_index] = fast_norm(s[it.multi_index])  # || x - w ||\n",
    "            it.iternext()\n",
    "\n",
    "    def activate(self, x):\n",
    "        \"\"\" Returns the activation map to x \"\"\"\n",
    "        self._activate(x)\n",
    "        return self.activation_map\n",
    "\n",
    "    def gaussian(self, c, sigma):\n",
    "        \"\"\" Returns a Gaussian centered in c \"\"\"\n",
    "        d = 2*pi*sigma*sigma\n",
    "        ax = exp(-power(self.neigx-c[0], 2)/d)\n",
    "        ay = exp(-power(self.neigy-c[1], 2)/d)\n",
    "        return outer(ax, ay)  # the external product gives a matrix\n",
    "\n",
    "    def diff_gaussian(self, c, sigma):\n",
    "        \"\"\" Mexican hat centered in c (unused) \"\"\"\n",
    "        xx, yy = meshgrid(self.neigx, self.neigy)\n",
    "        p = power(xx-c[0], 2) + power(yy-c[1], 2)\n",
    "        d = 2*pi*sigma*sigma\n",
    "        return exp(-p/d)*(1-2/d*p)\n",
    "\n",
    "    def winner(self, x):\n",
    "        \"\"\" Computes the coordinates of the winning neuron for the sample x \"\"\"\n",
    "        self._activate(x)\n",
    "        return unravel_index(self.activation_map.argmin(), self.activation_map.shape)\n",
    "\n",
    "    def update(self, x, win, t):\n",
    "        \"\"\"\n",
    "            Updates the weights of the neurons.\n",
    "            x - current pattern to learn\n",
    "            win - position of the winning neuron for x (array or tuple).\n",
    "            t - iteration index\n",
    "        \"\"\"\n",
    "        eta = self._decay_function(self.learning_rate, t, self.T)\n",
    "        sig = self._decay_function(self.sigma, t, self.T) # sigma and learning rate decrease with the same rule\n",
    "        g = self.neighborhood(win, sig)*eta # improves the performances\n",
    "        it = nditer(g, flags=['multi_index'])\n",
    "        while not it.finished:\n",
    "            # eta * neighborhood_function * (x-w)\n",
    "            self.weights[it.multi_index] += g[it.multi_index]*(x-self.weights[it.multi_index])\n",
    "            # normalization\n",
    "            self.weights[it.multi_index] = self.weights[it.multi_index] / fast_norm(self.weights[it.multi_index])\n",
    "            it.iternext()\n",
    "\n",
    "    def quantization(self, data):\n",
    "        \"\"\" Assigns a code book (weights vector of the winning neuron) to each sample in data. \"\"\"\n",
    "        q = zeros(data.shape)\n",
    "        for i, x in enumerate(data):\n",
    "            q[i] = self.weights[self.winner(x)]\n",
    "        return q\n",
    "\n",
    "    def random_weights_init(self, data):\n",
    "        \"\"\" Initializes the weights of the SOM picking random samples from data \"\"\"\n",
    "        it = nditer(self.activation_map, flags=['multi_index'])\n",
    "        while not it.finished:\n",
    "            self.weights[it.multi_index] = data[self.random_generator.randint(len(data))]\n",
    "            self.weights[it.multi_index] = self.weights[it.multi_index]/fast_norm(self.weights[it.multi_index])\n",
    "            it.iternext()\n",
    "\n",
    "    def train_random(self, data, num_iteration):\n",
    "        \"\"\" Trains the SOM picking samples at random from data \"\"\"\n",
    "        self._init_T(num_iteration)\n",
    "        for iteration in range(num_iteration):\n",
    "            rand_i = self.random_generator.randint(len(data)) # pick a random sample\n",
    "            self.update(data[rand_i], self.winner(data[rand_i]), iteration)\n",
    "\n",
    "    def train_batch(self, data, num_iteration):\n",
    "        \"\"\" Trains using all the vectors in data sequentially \"\"\"\n",
    "        self._init_T(len(data)*num_iteration)\n",
    "        iteration = 0\n",
    "        while iteration < num_iteration:\n",
    "            idx = iteration % (len(data)-1)\n",
    "            self.update(data[idx], self.winner(data[idx]), iteration)\n",
    "            iteration += 1\n",
    "\n",
    "    def _init_T(self, num_iteration):\n",
    "        \"\"\" Initializes the parameter T needed to adjust the learning rate \"\"\"\n",
    "        self.T = num_iteration/2  # keeps the learning rate nearly constant for the last half of the iterations\n",
    "\n",
    "    def distance_map(self):\n",
    "        \"\"\" Returns the distance map of the weights.\n",
    "            Each cell is the normalised sum of the distances between a neuron and its neighbours.\n",
    "        \"\"\"\n",
    "        um = zeros((self.weights.shape[0], self.weights.shape[1]))\n",
    "        it = nditer(um, flags=['multi_index'])\n",
    "        while not it.finished:\n",
    "            for ii in range(it.multi_index[0]-1, it.multi_index[0]+2):\n",
    "                for jj in range(it.multi_index[1]-1, it.multi_index[1]+2):\n",
    "                    if ii >= 0 and ii < self.weights.shape[0] and jj >= 0 and jj < self.weights.shape[1]:\n",
    "                        um[it.multi_index] += fast_norm(self.weights[ii, jj, :]-self.weights[it.multi_index])\n",
    "            it.iternext()\n",
    "        um = um/um.max()\n",
    "        return um\n",
    "\n",
    "    def activation_response(self, data):\n",
    "        \"\"\"\n",
    "            Returns a matrix where the element i,j is the number of times\n",
    "            that the neuron i,j have been winner.\n",
    "        \"\"\"\n",
    "        a = zeros((self.weights.shape[0], self.weights.shape[1]))\n",
    "        for x in data:\n",
    "            a[self.winner(x)] += 1\n",
    "        return a\n",
    "\n",
    "    def quantization_error(self, data):\n",
    "        \"\"\"\n",
    "            Returns the quantization error computed as the average distance between\n",
    "            each input sample and its best matching unit.\n",
    "        \"\"\"\n",
    "        error = 0\n",
    "        for x in data:\n",
    "            error += fast_norm(x-self.weights[self.winner(x)])\n",
    "        return error/len(data)\n",
    "\n",
    "    def win_map(self, data):\n",
    "        \"\"\"\n",
    "            Returns a dictionary wm where wm[(i,j)] is a list with all the patterns\n",
    "            that have been mapped in the position i,j.\n",
    "        \"\"\"\n",
    "        winmap = defaultdict(list)\n",
    "        for x in data:\n",
    "            winmap[self.winner(x)].append(x)\n",
    "        return winmap\n",
    "\n",
    "### unit tests\n",
    "# '''\n",
    "# from numpy.testing import assert_almost_equal, assert_array_almost_equal, assert_array_equal\n",
    "\n",
    "\n",
    "# class TestMinisom:\n",
    "#     def setup_method(self, method):\n",
    "#         self.som = MiniSom(5, 5, 1)\n",
    "#         for i in range(5):\n",
    "#             for j in range(5):\n",
    "#                 assert_almost_equal(1.0, linalg.norm(self.som.weights[i,j]))  # checking weights normalization\n",
    "#         self.som.weights = zeros((5, 5))  # fake weights\n",
    "#         self.som.weights[2, 3] = 5.0\n",
    "#         self.som.weights[1, 1] = 2.0\n",
    "\n",
    "#     def test_decay_function(self):\n",
    "#         assert self.som._decay_function(1., 2., 3.) == 1./(1.+2./3.)\n",
    "\n",
    "#     def test_fast_norm(self):\n",
    "#         assert fast_norm(array([1, 3])) == sqrt(1+9)\n",
    "\n",
    "#     def test_gaussian(self):\n",
    "#         bell = self.som.gaussian((2, 2), 1)\n",
    "#         assert bell.max() == 1.0\n",
    "#         assert bell.argmax() == 12  # unravel(12) = (2,2)\n",
    "\n",
    "#     def test_win_map(self):\n",
    "#         winners = self.som.win_map([5.0, 2.0])\n",
    "#         assert winners[(2, 3)][0] == 5.0\n",
    "#         assert winners[(1, 1)][0] == 2.0\n",
    "\n",
    "#     def test_activation_reponse(self):\n",
    "#         response = self.som.activation_response([5.0, 2.0])\n",
    "#         assert response[2, 3] == 1\n",
    "#         assert response[1, 1] == 1\n",
    "\n",
    "#     def test_activate(self):\n",
    "#         assert self.som.activate(5.0).argmin() == 13.0  # unravel(13) = (2,3)\n",
    "\n",
    "#     def test_quantization_error(self):\n",
    "#         self.som.quantization_error([5, 2]) == 0.0\n",
    "#         self.som.quantization_error([4, 1]) == 0.5\n",
    "\n",
    "#     def test_quantization(self):\n",
    "#         q = self.som.quantization(array([4, 2]))\n",
    "#         assert q[0] == 5.0\n",
    "#         assert q[1] == 2.0\n",
    "\n",
    "#     def test_random_seed(self):\n",
    "#         som1 = MiniSom(5, 5, 2, sigma=1.0, learning_rate=0.5, random_seed=1)\n",
    "#         som2 = MiniSom(5, 5, 2, sigma=1.0, learning_rate=0.5, random_seed=1)\n",
    "#         assert_array_almost_equal(som1.weights, som2.weights)  # same initialization\n",
    "#         data = random.rand(100,2)\n",
    "#         som1 = MiniSom(5, 5, 2, sigma=1.0, learning_rate=0.5, random_seed=1)\n",
    "#         som1.train_random(data,10)\n",
    "#         som2 = MiniSom(5, 5, 2, sigma=1.0, learning_rate=0.5, random_seed=1)\n",
    "#         som2.train_random(data,10)\n",
    "#         assert_array_almost_equal(som1.weights,som2.weights)  # same state after training\n",
    "\n",
    "#     def test_train_batch(self):\n",
    "#         som = MiniSom(5, 5, 2, sigma=1.0, learning_rate=0.5, random_seed=1)\n",
    "#         data = array([[4, 2], [3, 1]])\n",
    "#         q1 = som.quantization_error(data)\n",
    "#         som.train_batch(data, 10)\n",
    "#         assert q1 > som.quantization_error(data)\n",
    "\n",
    "#     def test_train_random(self):\n",
    "#         som = MiniSom(5, 5, 2, sigma=1.0, learning_rate=0.5, random_seed=1)\n",
    "#         data = array([[4, 2], [3, 1]])\n",
    "#         q1 = som.quantization_error(data)\n",
    "#         som.train_random(data, 10)\n",
    "#         assert q1 > som.quantization_error(data)\n",
    "\n",
    "#     def test_random_weights_init(self):\n",
    "#         som = MiniSom(2, 2, 2, random_seed=1)\n",
    "#         som.random_weights_init(array([[1.0, .0]]))\n",
    "#         for w in som.weights:\n",
    "#             assert_array_equal(w[0], array([1.0, .0]))\n",
    "\n",
    "\n",
    "\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "ceceb20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the SOM\n",
    "#from minisom import MiniSom\n",
    "som = MiniSom(x = 10, y = 10, input_len = 300, sigma = 1.0, learning_rate = 0.5)\n",
    "som.random_weights_init(word_vectors)\n",
    "som.train_random(data = word_vectors, num_iteration = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c5a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hdbscan -> 밀도기반 \n",
    "#문서 군집화 -> 밀도기반 \n",
    "#딥러닝 -> x (문서 분류, 문서 군집화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e423d87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11236012,  0.02490268,  0.02918391, ..., -0.14387944,\n",
       "        -0.05629704,  0.11514557],\n",
       "       [-0.18449359,  0.21177749,  0.02855687, ..., -0.29755563,\n",
       "        -0.10659172,  0.09030319],\n",
       "       [-0.17191753,  0.13481405, -0.00542197, ..., -0.26357353,\n",
       "        -0.07554129,  0.06220521],\n",
       "       ...,\n",
       "       [-0.05578983,  0.06594275,  0.00600702, ..., -0.09093149,\n",
       "        -0.03218354,  0.03526275],\n",
       "       [-0.07333402,  0.07885507,  0.00681297, ..., -0.10983935,\n",
       "        -0.03924961,  0.04143555],\n",
       "       [-0.06536539,  0.07210843,  0.005145  , ..., -0.10444382,\n",
       "        -0.03277766,  0.03602912]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574bdf47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bd47a36",
   "metadata": {},
   "source": [
    "### Spherical Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b2c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from soyclustering import SphericalKMeans\n",
    "\n",
    "spherical_kmeans = SphericalKMeans(\n",
    "    n_clusters=120,\n",
    "    max_iter=10,\n",
    "    verbose=1,\n",
    "    init='similar_cut'\n",
    ")\n",
    "\n",
    "labels = spherical_kmeans.fit_predict(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "78794766",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 100)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_csr_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "10266e1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>topic_idx</th>\n",
       "      <th>title_prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9724</th>\n",
       "      <td>9724</td>\n",
       "      <td>33429</td>\n",
       "      <td>줄리아니 러시아 후원행사에 돈받고 참가…美 제재대상도 배석</td>\n",
       "      <td>4</td>\n",
       "      <td>줄리아니 러시아 후원행사에 돈받고 참가   제재대상도 배석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>946</td>\n",
       "      <td>3259</td>\n",
       "      <td>일왕 신년인사…세계 안녕 기원</td>\n",
       "      <td>4</td>\n",
       "      <td>일왕 신년인사 세계 안녕 기원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10803</th>\n",
       "      <td>10803</td>\n",
       "      <td>37252</td>\n",
       "      <td>국토정보공사 전남공고에 4억 상당 실습 기자재 기증</td>\n",
       "      <td>2</td>\n",
       "      <td>국토정보공사 전남공고에  억 상당 실습 기자재 기증</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318</th>\n",
       "      <td>7318</td>\n",
       "      <td>23890</td>\n",
       "      <td>퇴직금 제도 개선 광주 5개구청 공무직노조 삭발투쟁</td>\n",
       "      <td>2</td>\n",
       "      <td>퇴직금 제도 개선 광주  개구청 공무직노조 삭발투쟁</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9386</th>\n",
       "      <td>9386</td>\n",
       "      <td>31803</td>\n",
       "      <td>박기수 신임 TBN 광주교통방송 본부장</td>\n",
       "      <td>2</td>\n",
       "      <td>박기수 신임 TBN 광주교통방송 본부장</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>905</td>\n",
       "      <td>3128</td>\n",
       "      <td>차세대 지휘자 찾아…서울시향 부지휘자 최초로 공개 모집</td>\n",
       "      <td>2</td>\n",
       "      <td>차세대 지휘자 찾아 서울시향 부지휘자 최초로 공개 모집</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>5192</td>\n",
       "      <td>17075</td>\n",
       "      <td>서양화 거장 장욱진 화백 기념관 세종시에 들어선다</td>\n",
       "      <td>2</td>\n",
       "      <td>서양화 거장 장욱진 화백 기념관 세종시에 들어선다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>12172</td>\n",
       "      <td>39911</td>\n",
       "      <td>내년도 최저임금 노사 입장차 팽팽</td>\n",
       "      <td>2</td>\n",
       "      <td>내년도 최저임금 노사 입장차 팽팽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>235</td>\n",
       "      <td>553</td>\n",
       "      <td>中 5G 지배하면 세계가 위험 전직 美NSC 장성 주장</td>\n",
       "      <td>4</td>\n",
       "      <td>G 지배하면 세계가 위험 전직  NSC 장성 주장</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13349</th>\n",
       "      <td>13349</td>\n",
       "      <td>42208</td>\n",
       "      <td>경주 동국대 코로나로 4·19 등반대회 취소…나무심기 대체</td>\n",
       "      <td>2</td>\n",
       "      <td>경주 동국대 코로나로      등반대회 취소 나무심기 대체</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11992 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  index                             title  topic_idx  \\\n",
       "9724         9724  33429  줄리아니 러시아 후원행사에 돈받고 참가…美 제재대상도 배석          4   \n",
       "946           946   3259                  일왕 신년인사…세계 안녕 기원          4   \n",
       "10803       10803  37252      국토정보공사 전남공고에 4억 상당 실습 기자재 기증          2   \n",
       "7318         7318  23890      퇴직금 제도 개선 광주 5개구청 공무직노조 삭발투쟁          2   \n",
       "9386         9386  31803             박기수 신임 TBN 광주교통방송 본부장          2   \n",
       "...           ...    ...                               ...        ...   \n",
       "905           905   3128    차세대 지휘자 찾아…서울시향 부지휘자 최초로 공개 모집          2   \n",
       "5192         5192  17075       서양화 거장 장욱진 화백 기념관 세종시에 들어선다          2   \n",
       "12172       12172  39911                내년도 최저임금 노사 입장차 팽팽          2   \n",
       "235           235    553    中 5G 지배하면 세계가 위험 전직 美NSC 장성 주장          4   \n",
       "13349       13349  42208  경주 동국대 코로나로 4·19 등반대회 취소…나무심기 대체          2   \n",
       "\n",
       "                             title_prep  \n",
       "9724   줄리아니 러시아 후원행사에 돈받고 참가   제재대상도 배석  \n",
       "946                    일왕 신년인사 세계 안녕 기원  \n",
       "10803      국토정보공사 전남공고에  억 상당 실습 기자재 기증  \n",
       "7318       퇴직금 제도 개선 광주  개구청 공무직노조 삭발투쟁  \n",
       "9386              박기수 신임 TBN 광주교통방송 본부장  \n",
       "...                                 ...  \n",
       "905      차세대 지휘자 찾아 서울시향 부지휘자 최초로 공개 모집  \n",
       "5192        서양화 거장 장욱진 화백 기념관 세종시에 들어선다  \n",
       "12172                내년도 최저임금 노사 입장차 팽팽  \n",
       "235         G 지배하면 세계가 위험 전직  NSC 장성 주장  \n",
       "13349  경주 동국대 코로나로      등반대회 취소 나무심기 대체  \n",
       "\n",
       "[11992 rows x 5 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[train_x.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f527469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b0711fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from soyclustering import proportion_keywords\n",
    "\n",
    "vocabs = [vocab for vocab, idx in sorted(vectorizer.vocabulary_.items(), key=lambda x:x[1])]\n",
    "centers = spherical_kmeans.cluster_centers_\n",
    "\n",
    "keywords = proportion_keywords(\n",
    "    centers,\n",
    "    labels=labels,\n",
    "    index2word=vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "11c2bd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ms', 0.5470385308104908),\n",
       " ('slbm', 0.5203993825826435),\n",
       " ('kist', 0.5101978754038107),\n",
       " ('강조', 0.50940572826508),\n",
       " ('가입자', 0.5080748105626114),\n",
       " ('fbi', 0.507249354227293),\n",
       " ('강등', 0.5061128334584735),\n",
       " ('가방', 0.5060430891619824),\n",
       " ('tpp', 0.505481949563363),\n",
       " ('가족', 0.5054054806461908),\n",
       " ('강경파', 0.5037942838062077),\n",
       " ('감사원장', 0.5035189299691097),\n",
       " ('가입', 0.5031958049261712),\n",
       " ('감사', 0.5027072452435142),\n",
       " ('kbs', 0.5022125262856764),\n",
       " ('강력', 0.5021358504574223),\n",
       " ('가정폭력', 0.5012223704540489),\n",
       " ('anc', 0.5008006435278909),\n",
       " ('가능성', 0.5001275895294155)]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7cc219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ba23f935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1599x100 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 159900 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sparse matrix 만들기\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "embedding_csr_matrix = csr_matrix(embedding_matrix)\n",
    "embedding_csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "af6a3b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x100 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 100 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_csr_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f4d009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('base': conda)",
   "language": "python",
   "name": "python382jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
